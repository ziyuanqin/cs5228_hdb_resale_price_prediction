{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113512,"databundleVersionId":13539341,"sourceType":"competition"},{"sourceId":13475972,"sourceType":"datasetVersion","datasetId":8555189}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:09.869177Z","iopub.execute_input":"2025-10-25T14:25:09.869490Z","iopub.status.idle":"2025-10-25T14:25:12.345229Z","shell.execute_reply.started":"2025-10-25T14:25:09.869466Z","shell.execute_reply":"2025-10-25T14:25:12.343672Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def data_cleaning(train):\n    # split 'MONTH' column into 'YEAR' and 'MONTH' columns\n    train[['YEAR', 'MONTH']] = train['MONTH'].str.split('-', expand=True).astype(int)\n    # ensure consistent formatting in 'FLAT_TYPE' column\n    train['FLAT_TYPE'] = train['FLAT_TYPE'].str.replace('-', ' ', regex=False)\n    # drop 'ECO_CATEGORY' column as it has the same value for all rows\n    train.drop(columns=['ECO_CATEGORY'], inplace=True)\n    # create 'FLAT_AGE' column and drop 'LEASE_COMMENCE_DATA' column\n    train['FLAT_AGE'] = train['YEAR'] - train['LEASE_COMMENCE_DATA']\n    train.drop(columns=['LEASE_COMMENCE_DATA'], inplace=True)\n    return train\n\ndef merge_hdb_info(train, hdb_info):\n    train[['BLOCK', 'STREET']] = train[['BLOCK', 'STREET']].apply(lambda x: x.str.lower())\n    hdb_info[['BLOCK', 'ADDRESS']] = hdb_info[['BLOCK', 'ADDRESS']].apply(lambda x: x.str.lower())\n    train_merge = train.merge(hdb_info, \n                          how='left', \n                          left_on=['BLOCK', 'STREET'], \n                          right_on=['BLOCK', 'ADDRESS'],\n                          indicator=True,\n                          suffixes=('', '_HDB'))\n    train_merge.drop(columns=['BLOCK', 'STREET', 'TOWN_HDB', 'ADDRESS', 'POSTAL_CODE', '_merge'], inplace=True)\n    return train_merge\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:14.898337Z","iopub.execute_input":"2025-10-25T14:25:14.898971Z","iopub.status.idle":"2025-10-25T14:25:14.907385Z","shell.execute_reply.started":"2025-10-25T14:25:14.898935Z","shell.execute_reply":"2025-10-25T14:25:14.905967Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"folder_path = \"/kaggle/input/cs-5228-2510-project/\"\ntrain = pd.read_csv(folder_path + 'train.csv', index_col= None)\ntrain.drop_duplicates(keep='first', inplace=True) # only drop duplicates in training set\ntest = pd.read_csv(folder_path + 'test.csv', index_col= None)\nhdb_info = pd.read_csv('/kaggle/input/hdbdata/sg-hdb-block-details.csv', index_col=None)\ncleaned_train = data_cleaning(train)\ncleaned_test = data_cleaning(test)\nmerged_train = merge_hdb_info(cleaned_train, hdb_info)\nmerged_test = merge_hdb_info(cleaned_test, hdb_info)\n# merged_train.to_csv('merged_train.csv', index=False)\n# merged_test.to_csv('merged_test.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:17.995513Z","iopub.execute_input":"2025-10-25T14:25:17.995868Z","iopub.status.idle":"2025-10-25T14:25:19.969366Z","shell.execute_reply.started":"2025-10-25T14:25:17.995839Z","shell.execute_reply":"2025-10-25T14:25:19.968288Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"merged_train.shape,merged_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:23.138480Z","iopub.execute_input":"2025-10-25T14:25:23.138827Z","iopub.status.idle":"2025-10-25T14:25:23.146574Z","shell.execute_reply.started":"2025-10-25T14:25:23.138802Z","shell.execute_reply":"2025-10-25T14:25:23.145288Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((162570, 15), (50000, 14))"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import KFold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:25.572280Z","iopub.execute_input":"2025-10-25T14:25:25.572627Z","iopub.status.idle":"2025-10-25T14:25:27.709310Z","shell.execute_reply.started":"2025-10-25T14:25:25.572565Z","shell.execute_reply":"2025-10-25T14:25:27.708132Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train = merged_train\ntest = merged_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:32.385487Z","iopub.execute_input":"2025-10-25T14:25:32.386365Z","iopub.status.idle":"2025-10-25T14:25:32.392029Z","shell.execute_reply.started":"2025-10-25T14:25:32.386332Z","shell.execute_reply":"2025-10-25T14:25:32.390821Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# reduce number of categories in FLAT_MODEL\nflat_model_map = {\n    '3gen': 'multi generation',\n    'model a maisonette': 'maisonette',\n    'improved maisonette': 'maisonette',\n    'premium maisonette': 'maisonette',\n    'premium apartment loft': 'premium apartment',\n    'type s1': 'new generation',\n    'type s2': 'new generation',\n    'model a2': 'model a'\n}\ntrain['FLAT_MODEL'] = train['FLAT_MODEL'].map(flat_model_map).fillna(train['FLAT_MODEL'])\ntest['FLAT_MODEL'] = test['FLAT_MODEL'].map(flat_model_map).fillna(test['FLAT_MODEL'])\ntrain['FLAT_MODEL'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:34.884878Z","iopub.execute_input":"2025-10-25T14:25:34.885256Z","iopub.status.idle":"2025-10-25T14:25:34.944989Z","shell.execute_reply.started":"2025-10-25T14:25:34.885223Z","shell.execute_reply":"2025-10-25T14:25:34.943722Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"FLAT_MODEL\nmodel a              59733\nimproved             39773\nnew generation       20299\npremium apartment    18186\nsimplified            6174\napartment             5891\nmaisonette            4838\nstandard              4363\ndbss                  2604\nadjoined flat          290\n2 room                 225\nmulti generation       109\nterrace                 85\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def mean_floor_range(floor_range):\n    if pd.isna(floor_range):\n        return np.nan\n    parts = floor_range.split(' to ')\n    if len(parts) != 2:\n        return np.nan\n    try:\n        low = int(parts[0])\n        high = int(parts[1])\n        return (low + high) / 2\n    except:\n        return np.nan\ntrain['FLOOR_RANGE'] = train['FLOOR_RANGE'].apply(mean_floor_range)\ntrain['FLOOR_RATIO'] = train['FLOOR_RANGE']/train['MAX_FLOOR']\ntest['FLOOR_RANGE'] = test['FLOOR_RANGE'].apply(mean_floor_range)\ntest['FLOOR_RATIO'] = test['FLOOR_RANGE']/test['MAX_FLOOR']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:39.122398Z","iopub.execute_input":"2025-10-25T14:25:39.122719Z","iopub.status.idle":"2025-10-25T14:25:39.366189Z","shell.execute_reply.started":"2025-10-25T14:25:39.122697Z","shell.execute_reply":"2025-10-25T14:25:39.364522Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def target_encode_cv(df, feature, target, n_splits=5, random_state=42):\n    df = df.copy()\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    encoded = np.zeros(len(df))\n    for train_index, val_index in kf.split(df):\n        train_fold, val_fold = df.iloc[train_index], df.iloc[val_index]\n        means = train_fold.groupby(feature)[target].mean()\n        encoded[val_index] = val_fold[feature].map(means)\n    # fill unseen categories with overall mean\n    overall_mean = df[target].mean()\n    encoded[np.isnan(encoded)] = overall_mean\n    return encoded\n\n# basic target encoding without CV\ndef target_encode(df, feature, target):\n    df = df.copy()\n    means = df.groupby(feature)[target].mean()\n    encoded = df[feature].map(means)\n    overall_mean = df[target].mean()\n    encoded[np.isnan(encoded)] = overall_mean\n    return encoded\n# target encoding for test set using train set means\ndef target_encode_test(train_df, test_df, feature, target):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    means = train_df.groupby(feature)[target].mean()\n    test_encoded = test_df[feature].map(means)\n    overall_mean = train_df[target].mean()\n    test_encoded[np.isnan(test_encoded)] = overall_mean\n    return test_encoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:46.763477Z","iopub.execute_input":"2025-10-25T14:25:46.763808Z","iopub.status.idle":"2025-10-25T14:25:46.772485Z","shell.execute_reply.started":"2025-10-25T14:25:46.763786Z","shell.execute_reply":"2025-10-25T14:25:46.771440Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def feat_encoding(data):\n    df = data.copy()\n    scaler = StandardScaler()\n    df[['FLOOR_AREA_SQM', 'FLAT_AGE']] = scaler.fit_transform(df[['FLOOR_AREA_SQM', 'FLAT_AGE']])\n    flat_type_order = ['1 room', '2 room', '3 room', '4 room', '5 room', 'executive', 'multi generation']\n    encoder = OrdinalEncoder(categories=[flat_type_order])\n    df['FLAT_TYPE'] = encoder.fit_transform(df[['FLAT_TYPE']])\n    df = pd.get_dummies(df, columns=['REGION', 'FLAT_MODEL'], prefix=['region', 'model'])\n    if 'RESALE_PRICE' in df.columns:\n        df['TOWN'] = target_encode_cv(df, 'TOWN', 'LOG_RESALE_PRICE')\n    else:\n        df['TOWN'] = target_encode_test(train, df, 'TOWN', 'LOG_RESALE_PRICE')\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:49.893197Z","iopub.execute_input":"2025-10-25T14:25:49.893489Z","iopub.status.idle":"2025-10-25T14:25:49.900399Z","shell.execute_reply.started":"2025-10-25T14:25:49.893470Z","shell.execute_reply":"2025-10-25T14:25:49.899200Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train['LOG_RESALE_PRICE'] = np.log(train['RESALE_PRICE'])\ntrain_encoded = feat_encoding(train)\ntest_encoded = feat_encoding(test)\ntrain_encoded.shape, test_encoded.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:52.755959Z","iopub.execute_input":"2025-10-25T14:25:52.756270Z","iopub.status.idle":"2025-10-25T14:25:53.384105Z","shell.execute_reply.started":"2025-10-25T14:25:52.756249Z","shell.execute_reply":"2025-10-25T14:25:53.382492Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"((162570, 33), (50000, 31))"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"train_encoded.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:56.213772Z","iopub.execute_input":"2025-10-25T14:25:56.214095Z","iopub.status.idle":"2025-10-25T14:25:56.221279Z","shell.execute_reply.started":"2025-10-25T14:25:56.214073Z","shell.execute_reply":"2025-10-25T14:25:56.220330Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Index(['MONTH', 'TOWN', 'FLAT_TYPE', 'FLOOR_RANGE', 'FLOOR_AREA_SQM',\n       'RESALE_PRICE', 'YEAR', 'FLAT_AGE', 'LATITUDE', 'LONGITUDE',\n       'MAX_FLOOR', 'SUBZONE', 'PLANNING_AREA', 'FLOOR_RATIO',\n       'LOG_RESALE_PRICE', 'region_central region', 'region_east region',\n       'region_north region', 'region_north-east region', 'region_west region',\n       'model_2 room', 'model_adjoined flat', 'model_apartment', 'model_dbss',\n       'model_improved', 'model_maisonette', 'model_model a',\n       'model_multi generation', 'model_new generation',\n       'model_premium apartment', 'model_simplified', 'model_standard',\n       'model_terrace'],\n      dtype='object')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"train_encoded.drop(columns=['FLOOR_RANGE', 'SUBZONE', 'PLANNING_AREA'], inplace=True)\ntest_encoded.drop(columns=['FLOOR_RANGE', 'SUBZONE', 'PLANNING_AREA'], inplace=True)\n\ntrain_encoded.to_csv(\"train_encoded.csv\", index = False)\ntest_encoded.to_csv(\"test_encoded.csv\", index = False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:25:59.612215Z","iopub.execute_input":"2025-10-25T14:25:59.612709Z","iopub.status.idle":"2025-10-25T14:26:03.640190Z","shell.execute_reply.started":"2025-10-25T14:25:59.612670Z","shell.execute_reply":"2025-10-25T14:26:03.638705Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor, early_stopping, log_evaluation\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nrmse_scores = []\n\ny = train_encoded['LOG_RESALE_PRICE']\nX = train_encoded.drop(columns=['LOG_RESALE_PRICE'])\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n    model = LGBMRegressor(\n        n_estimators=1000,\n        learning_rate=0.05,\n        num_leaves=31,\n        random_state=42,\n    )\n\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_metric=\"rmse\",\n        callbacks=[early_stopping(100), log_evaluation(0)],\n    )\n    \n    preds = model.predict(X_valid)\n\n    y_valid_exp = np.expm1(y_valid)\n    preds_exp = np.expm1(preds)\n    \n    rmse = mean_squared_error(y_valid_exp, preds_exp, squared=False)\n    rmse_scores.append(rmse)\n    print(f\"Fold {fold+1} RMSE: {rmse:.4f}\")\n\nprint(\"Average RMSE:\", np.mean(rmse_scores))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:36:00.822770Z","iopub.execute_input":"2025-10-25T14:36:00.823124Z","iopub.status.idle":"2025-10-25T14:36:21.476769Z","shell.execute_reply.started":"2025-10-25T14:36:00.823101Z","shell.execute_reply":"2025-10-25T14:36:21.475446Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003904 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1359\n[LightGBM] [Info] Number of data points in the train set: 130056, number of used features: 29\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Start training from score 13.100523\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[149]\tvalid_0's rmse: 0.00378124\tvalid_0's l2: 1.42978e-05\nFold 1 RMSE: 2089.1052\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002692 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1357\n[LightGBM] [Info] Number of data points in the train set: 130056, number of used features: 29\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Start training from score 13.099515\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[289]\tvalid_0's rmse: 0.00405618\tvalid_0's l2: 1.64526e-05\nFold 2 RMSE: 2036.5259\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003971 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1360\n[LightGBM] [Info] Number of data points in the train set: 130056, number of used features: 29\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Start training from score 13.099961\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[141]\tvalid_0's rmse: 0.00329958\tvalid_0's l2: 1.08873e-05\nFold 3 RMSE: 1761.3577\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002749 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1362\n[LightGBM] [Info] Number of data points in the train set: 130056, number of used features: 29\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Start training from score 13.099625\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[190]\tvalid_0's rmse: 0.00339288\tvalid_0's l2: 1.15116e-05\nFold 4 RMSE: 2087.9499\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002848 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1359\n[LightGBM] [Info] Number of data points in the train set: 130056, number of used features: 29\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Start training from score 13.099876\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[252]\tvalid_0's rmse: 0.00358238\tvalid_0's l2: 1.28335e-05\nFold 5 RMSE: 1767.3878\nAverage RMSE: 1948.4653255619614\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\ny_raw = np.expm1(y)   # Real price\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\ndef evaluate_model(model, X, y, model_name=\"Model\"):\n    log_rmse_list, real_rmse_list, mape_list = [], [], []\n    for fold, (tr_idx, va_idx) in enumerate(kf.split(X), 1):\n        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n        y_tr_log, y_va_log = y.iloc[tr_idx], y.iloc[va_idx]\n        y_va_raw = y_raw.iloc[va_idx]\n\n        model.fit(X_tr, y_tr_log)\n        preds_log = model.predict(X_va)\n\n        rmse_log = mean_squared_error(y_va_log, preds_log, squared=False)\n        preds_raw = np.expm1(preds_log)\n        rmse_real = mean_squared_error(y_va_raw, preds_raw, squared=False)\n        mape = mean_absolute_percentage_error(y_va_raw, preds_raw) * 100\n\n        log_rmse_list.append(rmse_log)\n        real_rmse_list.append(rmse_real)\n        mape_list.append(mape)\n\n        print(f\"Fold {fold}: logRMSE={rmse_log:.5f}, realRMSE={rmse_real:.2f}, MAPE={mape:.2f}%\")\n\n    print(\"\\n=== Summary for\", model_name, \"===\")\n    print(f\"Average logRMSE : {np.mean(log_rmse_list):.5f}\")\n    print(f\"Average realRMSE: {np.mean(real_rmse_list):.2f}\")\n    print(f\"Average MAPE    : {np.mean(mape_list):.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:13:50.089430Z","iopub.execute_input":"2025-10-25T15:13:50.089772Z","iopub.status.idle":"2025-10-25T15:13:50.100503Z","shell.execute_reply.started":"2025-10-25T15:13:50.089749Z","shell.execute_reply":"2025-10-25T15:13:50.099318Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nevaluate_model(model, X, y, \"Linear Regression\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:14:03.705175Z","iopub.execute_input":"2025-10-25T15:14:03.706222Z","iopub.status.idle":"2025-10-25T15:14:05.124822Z","shell.execute_reply.started":"2025-10-25T15:14:03.706190Z","shell.execute_reply":"2025-10-25T15:14:05.123876Z"}},"outputs":[{"name":"stdout","text":"Fold 1: logRMSE=0.05947, realRMSE=46249.80, MAPE=4.37%\nFold 2: logRMSE=0.05994, realRMSE=47373.51, MAPE=4.39%\nFold 3: logRMSE=0.05913, realRMSE=47286.75, MAPE=4.33%\nFold 4: logRMSE=0.05970, realRMSE=48226.86, MAPE=4.38%\nFold 5: logRMSE=0.05887, realRMSE=45347.94, MAPE=4.36%\n\n=== Summary for Linear Regression ===\nAverage logRMSE : 0.05942\nAverage realRMSE: 46896.97\nAverage MAPE    : 4.37%\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=1.0, random_state=42)\nevaluate_model(model, X, y, \"Ridge Regression\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:14:18.348834Z","iopub.execute_input":"2025-10-25T15:14:18.349139Z","iopub.status.idle":"2025-10-25T15:14:18.812142Z","shell.execute_reply.started":"2025-10-25T15:14:18.349120Z","shell.execute_reply":"2025-10-25T15:14:18.811202Z"}},"outputs":[{"name":"stdout","text":"Fold 1: logRMSE=0.05947, realRMSE=46282.76, MAPE=4.36%\nFold 2: logRMSE=0.05994, realRMSE=47419.21, MAPE=4.39%\nFold 3: logRMSE=0.05913, realRMSE=47323.12, MAPE=4.33%\nFold 4: logRMSE=0.05971, realRMSE=48263.28, MAPE=4.38%\nFold 5: logRMSE=0.05886, realRMSE=45355.00, MAPE=4.36%\n\n=== Summary for Ridge Regression ===\nAverage logRMSE : 0.05942\nAverage realRMSE: 46928.67\nAverage MAPE    : 4.36%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=0.0005, max_iter=20000, random_state=42)\nevaluate_model(model, X, y, \"Lasso Regression\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:14:28.554258Z","iopub.execute_input":"2025-10-25T15:14:28.554565Z","iopub.status.idle":"2025-10-25T15:14:31.777334Z","shell.execute_reply.started":"2025-10-25T15:14:28.554544Z","shell.execute_reply":"2025-10-25T15:14:31.776641Z"}},"outputs":[{"name":"stdout","text":"Fold 1: logRMSE=0.06136, realRMSE=48458.04, MAPE=4.42%\nFold 2: logRMSE=0.06179, realRMSE=50059.09, MAPE=4.44%\nFold 3: logRMSE=0.06108, realRMSE=49723.54, MAPE=4.40%\nFold 4: logRMSE=0.06154, realRMSE=50526.99, MAPE=4.43%\nFold 5: logRMSE=0.06081, realRMSE=46953.70, MAPE=4.42%\n\n=== Summary for Lasso Regression ===\nAverage logRMSE : 0.06132\nAverage realRMSE: 49144.27\nAverage MAPE    : 4.42%\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmodel = XGBRegressor(\n    n_estimators=1500,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    reg_lambda=1.0,\n    tree_method=\"hist\",\n    n_jobs=-1,\n    random_state=42\n)\nevaluate_model(model, X, y, \"XGBoost\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:19:59.609396Z","iopub.execute_input":"2025-10-25T15:19:59.609718Z","iopub.status.idle":"2025-10-25T15:21:11.473720Z","shell.execute_reply.started":"2025-10-25T15:19:59.609694Z","shell.execute_reply":"2025-10-25T15:21:11.472172Z"}},"outputs":[{"name":"stdout","text":"Fold 1: logRMSE=0.00608, realRMSE=4450.35, MAPE=0.32%\nFold 2: logRMSE=0.00628, realRMSE=5186.94, MAPE=0.31%\nFold 3: logRMSE=0.00576, realRMSE=4351.43, MAPE=0.31%\nFold 4: logRMSE=0.00582, realRMSE=4767.50, MAPE=0.31%\nFold 5: logRMSE=0.00584, realRMSE=4453.47, MAPE=0.31%\n\n=== Summary for XGBoost ===\nAverage logRMSE : 0.00596\nAverage realRMSE: 4641.94\nAverage MAPE    : 0.31%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from sklearn.svm import SVR\n\nmodel = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"svr\", SVR(C=5.0, epsilon=0.1, kernel=\"rbf\"))\n])\nevaluate_model(model, X, y, \"Support Vector Regression (RBF)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:22:32.650442Z","iopub.execute_input":"2025-10-25T15:22:32.651296Z","iopub.status.idle":"2025-10-25T15:23:46.455174Z","shell.execute_reply.started":"2025-10-25T15:22:32.651261Z","shell.execute_reply":"2025-10-25T15:23:46.453864Z"}},"outputs":[{"name":"stdout","text":"Fold 1: logRMSE=0.03766, realRMSE=19876.82, MAPE=3.00%\nFold 2: logRMSE=0.03625, realRMSE=19444.71, MAPE=2.84%\nFold 3: logRMSE=0.03855, realRMSE=20045.16, MAPE=3.08%\nFold 4: logRMSE=0.03825, realRMSE=20117.67, MAPE=3.05%\nFold 5: logRMSE=0.03857, realRMSE=20837.48, MAPE=3.03%\n\n=== Summary for Support Vector Regression (RBF) ===\nAverage logRMSE : 0.03786\nAverage realRMSE: 20064.37\nAverage MAPE    : 3.00%\n","output_type":"stream"}],"execution_count":29}]}