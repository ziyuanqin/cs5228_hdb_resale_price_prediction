{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac51340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 97542 rows\n",
      "Validation: 32514 rows\n",
      "Test: 32514 rows\n",
      "Train shapes: X=(97542, 36), y=(97542,)\n",
      "Val shapes:   X=(32514, 36), y=(32514,)\n",
      "Test shapes:  X=(32514, 36), y=(32514,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"final_train.csv\")\n",
    "final_test_df=pd.read_csv(\"final_test.csv\")\n",
    "\n",
    "#Split into train + temp (which will later be split into val/test)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "\n",
    "#Split temp into validation and test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check sizes\n",
    "print(f\"Train: {len(train_df)} rows\")\n",
    "print(f\"Validation: {len(val_df)} rows\")\n",
    "print(f\"Test: {len(test_df)} rows\")\n",
    "\n",
    "# train_df.to_csv(\"dataset/data_split/train.csv\", index=False)\n",
    "# val_df.to_csv(\"dataset/data_split/validate.csv\", index=False)\n",
    "# test_df.to_csv(\"dataset/data_split/test.csv\", index=False)\n",
    "\n",
    "# Define target column name\n",
    "target_col = \"LOG_RESALE_PRICE\"\n",
    "\n",
    "# Split into X (features) and y (target)\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_val = val_df.drop(columns=[target_col])\n",
    "y_val = val_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "X_full_train=df.drop(columns=[target_col])\n",
    "y_full_train=df[target_col]\n",
    "\n",
    "print(f\"Train shapes: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Val shapes:   X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Test shapes:  X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0848ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"DIST_PRIM\",\"DIST_HAWKER\",\"MONTH\",\"COUNT_SEC\"\n",
    "#low_corr=[\"DIST_PRIM\",\"DIST_HAWKER\",\"MONTH\",\"COUNT_SEC\"]\n",
    "#low_corr=[\"DIST_PRIM\",\"COUNT_SEC\"]\n",
    "low_corr=[\"DIST_PRIM\"]\n",
    "X_train_compare=X_train.drop(columns=low_corr)\n",
    "X_val_compare=X_val.drop(columns=low_corr)\n",
    "X_col_compare=X_test.drop(columns=low_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2ba7f",
   "metadata": {},
   "source": [
    "Linear model x  \n",
    "Lasso model x  \n",
    "ENet model  \n",
    "SVR model  \n",
    "Random Forest model  \n",
    "XGB model  \n",
    "LightGBM model x  \n",
    "Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c49b2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "results = []\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test, name=\"Model\"):\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "    mae_test = mean_absolute_error(y_test, test_pred)\n",
    "    r2_test = r2_score(y_test, test_pred)\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"Validation RMSE: {rmse_val:.4f}\")\n",
    "    print(f\"Test RMSE:       {rmse_test:.4f}\")\n",
    "    print(f\"Test MAE:        {mae_test:.4f}\")\n",
    "    print(f\"Test R²:         {r2_test:.3f}\")\n",
    "    #return {\"model\": name, \"val_rmse\": rmse_val, \"test_rmse\": rmse_test, \"test_mae\": mae_test, \"test_r2\": r2_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b00e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear model Evaluation:\n",
      "Validation RMSE: 0.1104\n",
      "Test RMSE:       0.1112\n",
      "Test MAE:        0.0862\n",
      "Test R²:         0.896\n",
      "None\n",
      "\n",
      "Linear model_drop Evaluation:\n",
      "Validation RMSE: 0.1104\n",
      "Test RMSE:       0.1112\n",
      "Test MAE:        0.0862\n",
      "Test R²:         0.896\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Linear model\n",
    "m_linear = LinearRegression()\n",
    "m_linear.fit(X_train, y_train)\n",
    "print(evaluate_model(m_linear, X_val, y_val, X_test, y_test, \"Linear model\"))\n",
    "\n",
    "m_linear.fit(X_train_compare, y_train)\n",
    "print(evaluate_model(m_linear, X_val_compare, y_val, X_col_compare, y_test, \"Linear model_drop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1646804d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.0001\n",
      "\n",
      "Lasso model Evaluation:\n",
      "Validation RMSE: 0.1104\n",
      "Test RMSE:       0.1112\n",
      "Test MAE:        0.0862\n",
      "Test R²:         0.896\n"
     ]
    }
   ],
   "source": [
    "# adaptive lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "alphas = np.logspace(-4, 2, 50)  # 1e-4 到 1e2 的对数网格\n",
    "m = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso\", LassoCV(alphas=alphas, cv=5, max_iter=10000, tol=1e-4, random_state=0))\n",
    "])\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = m.named_steps[\"lasso\"].alpha_\n",
    "coef = m.named_steps[\"lasso\"].coef_\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "evaluate_model(m, X_val, y_val, X_test, y_test, \"Lasso model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENetCV(best) Evaluation:\n",
      "Validation RMSE: 0.1104\n",
      "Test RMSE:       0.1112\n",
      "Test MAE:        0.0862\n",
      "Test R²:         0.896\n"
     ]
    }
   ],
   "source": [
    "# adaptive enet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "alphas = np.logspace(-4, 2, 60)             # 1e-4 ~ 1e2\n",
    "l1s    = np.concatenate([np.linspace(0.05, 0.95, 10), [1.0]])  # 含纯 Lasso\n",
    "\n",
    "enet_cv = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"enet\", ElasticNetCV(\n",
    "        alphas=alphas,\n",
    "        l1_ratio=l1s,\n",
    "        cv=5,\n",
    "        max_iter=10000,\n",
    "        tol=1e-4,\n",
    "        selection=\"cyclic\",   # 可换 'random' 试试\n",
    "        random_state=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "enet_cv.fit(X_train, y_train)\n",
    "\n",
    "best_alpha   = enet_cv.named_steps[\"enet\"].alpha_\n",
    "best_l1ratio = enet_cv.named_steps[\"enet\"].l1_ratio_\n",
    "best_coef    = enet_cv.named_steps[\"enet\"].coef_\n",
    "\n",
    "# 接到你的评测框架\n",
    "results.append(evaluate_model(enet_cv, X_val, y_val, X_test, y_test, \"ENetCV(best)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c39beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest model Evaluation:\n",
      "Validation RMSE: 0.0572\n",
      "Test RMSE:       0.0578\n",
      "Test MAE:        0.0424\n",
      "Test R²:         0.972\n",
      "None\n",
      "\n",
      "Random Forest model_drop Evaluation:\n",
      "Validation RMSE: 0.0571\n",
      "Test RMSE:       0.0576\n",
      "Test MAE:        0.0423\n",
      "Test R²:         0.972\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Random Forest model\n",
    "m_rf = RandomForestRegressor(random_state=42)\n",
    "m_rf.fit(X_train, y_train)\n",
    "print(evaluate_model(m_rf, X_val, y_val, X_test, y_test, \"Random Forest model\"))\n",
    "\n",
    "m_rf.fit(X_train_compare, y_train)\n",
    "print(evaluate_model(m_rf, X_val_compare, y_val, X_col_compare, y_test, \"Random Forest model_drop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787a9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 XGB model\n",
    "from xgboost import XGBRegressor\n",
    "m_xgb = None\n",
    "m_xgb = XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=100, max_depth=6, learning_rate=0.3,\n",
    "    subsample=1.0, colsample_bytree=1.0, reg_lambda=1.0,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "# m_xgb.fit(X_train, y_train)\n",
    "# print(evaluate_model(m_xgb, X_val, y_val, X_test, y_test, \"XGB model\"))\n",
    "\n",
    "# m_xgb.fit(X_train_compare, y_train)\n",
    "# print(evaluate_model(m_xgb, X_val_compare, y_val, X_col_compare, y_test, \"XGB model_drop\"))\n",
    "\n",
    "m_xgb.fit(X_full_train, y_full_train)\n",
    "y_pred_full = m_xgb.predict(final_test_df)\n",
    "y_pred_full_real = np.expm1(y_pred_full)\n",
    "df_pred = pd.DataFrame({\n",
    "    \"Id\": np.arange(len(y_pred_full_real)),\n",
    "    \"Predicted\": y_pred_full_real\n",
    "})\n",
    "df_pred.to_csv(\"xgb_full_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "790927ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 97542, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100217\n",
      "\n",
      "LightGBM model Evaluation:\n",
      "Validation RMSE: 0.0653\n",
      "Test RMSE:       0.0657\n",
      "Test MAE:        0.0498\n",
      "Test R²:         0.964\n",
      "None\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1363\n",
      "[LightGBM] [Info] Number of data points in the train set: 97542, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 13.100217\n",
      "\n",
      "LightGBM model_drop Evaluation:\n",
      "Validation RMSE: 0.0679\n",
      "Test RMSE:       0.0683\n",
      "Test MAE:        0.0522\n",
      "Test R²:         0.961\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3.7 LightGBM model\n",
    "from lightgbm import LGBMRegressor\n",
    "m_lgbm = None\n",
    "m_lgbm = LGBMRegressor(random_state=42)\n",
    "m_lgbm.fit(X_train, y_train)\n",
    "print(evaluate_model(m_lgbm, X_val, y_val, X_test, y_test, \"LightGBM model\"))\n",
    "\n",
    "m_lgbm.fit(X_train_compare, y_train)\n",
    "print(evaluate_model(m_lgbm, X_val_compare, y_val, X_col_compare, y_test, \"LightGBM model_drop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e5ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5228",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
