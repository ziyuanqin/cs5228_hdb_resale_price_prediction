{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d20cd65-d6a4-4a58-8813-76130fa213bd",
   "metadata": {},
   "source": [
    "train,val,test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cdf21a-9b80-43a5-ae9e-2ca210ebc40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 97542 rows\n",
      "Validation: 32514 rows\n",
      "Test: 32514 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"final_train.csv\")\n",
    "\n",
    "#Split into train + temp (which will later be split into val/test)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "\n",
    "#Split temp into validation and test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check sizes\n",
    "print(f\"Train: {len(train_df)} rows\")\n",
    "print(f\"Validation: {len(val_df)} rows\")\n",
    "print(f\"Test: {len(test_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22be207-b7bf-4d10-b6f4-b7abb192b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"dataset/data_split/train.csv\", index=False)\n",
    "val_df.to_csv(\"dataset/data_split/validate.csv\", index=False)\n",
    "test_df.to_csv(\"dataset/data_split/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09749bc7-3fa1-4b0a-80c5-0d0f7fcdefb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: X=(97542, 36), y=(97542,)\n",
      "Val shapes:   X=(32514, 36), y=(32514,)\n",
      "Test shapes:  X=(32514, 36), y=(32514,)\n"
     ]
    }
   ],
   "source": [
    "# Define target column name\n",
    "target_col = \"LOG_RESALE_PRICE\"\n",
    "\n",
    "# Split into X (features) and y (target)\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_val = val_df.drop(columns=[target_col])\n",
    "y_val = val_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "print(f\"Train shapes: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Val shapes:   X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"Test shapes:  X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98190327-8b00-42af-b342-43151ae40dbc",
   "metadata": {},
   "source": [
    "model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bc5a7cd-b133-4f5b-a07e-5edb75e70b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, X_test, y_test, name=\"Model\"):\n",
    "    val_pred = model.predict(X_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"Validation RMSE: {np.sqrt(mean_squared_error(y_val, val_pred)):.4f}\")\n",
    "    print(f\"Test RMSE:       {np.sqrt(mean_squared_error(y_test, test_pred)):.4f}\")\n",
    "    print(f\"Test MAE:        {mean_absolute_error(y_test, test_pred):.4f}\")\n",
    "    print(f\"Test R²:         {r2_score(y_test, test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65b0dc-86c2-456b-bb22-cbe36a4a5371",
   "metadata": {},
   "source": [
    "Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7437eb6-712c-40ba-be2f-7d7c373c96fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Evaluation:\n",
      "Validation RMSE: 0.1104\n",
      "Test RMSE:       0.1112\n",
      "Test MAE:        0.0862\n",
      "Test R²:         0.896\n"
     ]
    }
   ],
   "source": [
    "# --- Linear Regression ---\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "evaluate_model(lr, X_val, y_val, X_test, y_test, \"Linear Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69cfe67e-ec0d-46bb-be8b-c30c05c4cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression Evaluation:\n",
      "Validation RMSE: 0.1104\n",
      "Test RMSE:       0.1112\n",
      "Test MAE:        0.0862\n",
      "Test R²:         0.896\n"
     ]
    }
   ],
   "source": [
    "# --- Ridge Regression (with tuning) ---\n",
    "ridge_params = {'alpha': [0.1, 1, 10, 50]}\n",
    "ridge = GridSearchCV(Ridge(), ridge_params, cv=3, scoring='neg_root_mean_squared_error')\n",
    "ridge.fit(X_train, y_train)\n",
    "evaluate_model(ridge.best_estimator_, X_val, y_val, X_test, y_test, \"Ridge Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6768c65-5899-4d5b-8a8a-f42471572cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Evaluation:\n",
      "Validation RMSE: 0.1125\n",
      "Test RMSE:       0.1139\n",
      "Test MAE:        0.0879\n",
      "Test R²:         0.891\n"
     ]
    }
   ],
   "source": [
    "# --- Lasso Regression (with tuning) ---\n",
    "lasso_params = {'alpha': [0.001, 0.01, 0.1, 1]}\n",
    "lasso = GridSearchCV(Lasso(max_iter=10000), lasso_params, cv=3, scoring='neg_root_mean_squared_error')\n",
    "lasso.fit(X_train, y_train)\n",
    "evaluate_model(lasso.best_estimator_, X_val, y_val, X_test, y_test, \"Lasso Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c71455-4201-44f3-8368-5110fe370476",
   "metadata": {},
   "source": [
    "RandomForest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae2207c-4e5a-461f-ac04-1ce784155681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Evaluation:\n",
      "Validation RMSE: 0.0570\n",
      "Test RMSE:       0.0576\n",
      "Test MAE:        0.0423\n",
      "Test R²:         0.972\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest (Bagging) ---\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "rf = GridSearchCV(RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "                  rf_params, cv=3, scoring='neg_root_mean_squared_error')\n",
    "rf.fit(X_train, y_train)\n",
    "evaluate_model(rf.best_estimator_, X_val, y_val, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd2de0-0dd2-4767-b513-e453756eb39c",
   "metadata": {},
   "source": [
    "XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1e1207-bbb2-4586-b994-203ae430f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "XGBoost Evaluation:\n",
      "Validation RMSE: 0.0501\n",
      "Test RMSE:       0.0504\n",
      "Test MAE:        0.0374\n",
      "Test R²:         0.979\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost ---\n",
    "xgb_params = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [6, 10],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "xgb = GridSearchCV(XGBRegressor(random_state=42, n_jobs=-1),\n",
    "                   xgb_params, cv=3, scoring='neg_root_mean_squared_error', verbose=1)\n",
    "xgb.fit(X_train, y_train)\n",
    "evaluate_model(xgb.best_estimator_, X_val, y_val, X_test, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25f9a39c-4a0c-4f6c-b4d4-ef9c02b304ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1861\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100498\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1869\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.099826\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1860\n",
      "[LightGBM] [Info] Number of data points in the train set: 65028, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100327\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1895\n",
      "[LightGBM] [Info] Number of data points in the train set: 97542, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 13.100217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM Evaluation:\n",
      "Validation RMSE: 0.0514\n",
      "Test RMSE:       0.0514\n",
      "Test MAE:        0.0384\n",
      "Test R²:         0.978\n"
     ]
    }
   ],
   "source": [
    "# --- LightGBM ---\n",
    "lgbm_params = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 63],\n",
    "    'max_depth': [-1, 10]\n",
    "}\n",
    "lgbm = GridSearchCV(LGBMRegressor(random_state=42),\n",
    "                    lgbm_params, cv=3, scoring='neg_root_mean_squared_error', verbose=1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "evaluate_model(lgbm.best_estimator_, X_val, y_val, X_test, y_test, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3462a6f2-27d0-462d-955c-9ad8247f0167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3310822\ttest: 0.3321869\tbest: 0.3321869 (0)\ttotal: 77.7ms\tremaining: 38.8s\n",
      "100:\tlearn: 0.0809688\ttest: 0.0820034\tbest: 0.0820034 (100)\ttotal: 836ms\tremaining: 3.3s\n",
      "200:\tlearn: 0.0670162\ttest: 0.0682304\tbest: 0.0682304 (200)\ttotal: 1.62s\tremaining: 2.41s\n",
      "300:\tlearn: 0.0602926\ttest: 0.0619005\tbest: 0.0619005 (300)\ttotal: 2.27s\tremaining: 1.5s\n",
      "400:\tlearn: 0.0565324\ttest: 0.0584757\tbest: 0.0584757 (400)\ttotal: 2.89s\tremaining: 713ms\n",
      "499:\tlearn: 0.0540971\ttest: 0.0563712\tbest: 0.0563712 (499)\ttotal: 3.49s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.05637116981\n",
      "bestIteration = 499\n",
      "\n",
      "\n",
      "CatBoost Evaluation:\n",
      "Validation RMSE: 0.0564\n",
      "Test RMSE:       0.0567\n",
      "Test MAE:        0.0426\n",
      "Test R²:         0.973\n"
     ]
    }
   ],
   "source": [
    "# --- CatBoost ---\n",
    "cat = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    verbose=100,\n",
    "    random_state=42\n",
    ")\n",
    "cat.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "evaluate_model(cat, X_val, y_val, X_test, y_test, \"CatBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f9127-d5b4-4eb6-994c-1783e42dfcfe",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1305a5e-3ab1-4b4e-8743-770ead5d16a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "\n",
      "KNN Regressor Evaluation:\n",
      "Validation RMSE: 0.0865\n",
      "Test RMSE:       0.0866\n",
      "Test MAE:        0.0645\n",
      "Test R²:         0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Simple Grid Search\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1=Manhattan, 2=Euclidean\n",
    "}\n",
    "\n",
    "knn = GridSearchCV(KNeighborsRegressor(), knn_params, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", knn.best_params_)\n",
    "\n",
    "evaluate_model(knn.best_estimator_, X_val, y_val, X_test, y_test, \"KNN Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6434a5d-65cb-4e78-a59d-04a9f83a298f",
   "metadata": {},
   "source": [
    "DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f07e76cb-cb42-4a5b-8f37-ab3d2b646d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangzhou/miniconda3/envs/cs5228_assignment/lib/python3.13/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-10-25 16:22:50.201287: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 - 2s - 4ms/step - loss: 5.5348 - mean_squared_error: 230.3778 - val_loss: 0.2986 - val_mean_squared_error: 0.1378\n",
      "Epoch 2/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.7690 - mean_squared_error: 1.0447 - val_loss: 1.1978 - val_mean_squared_error: 1.5434\n",
      "Epoch 3/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.7144 - mean_squared_error: 0.8630 - val_loss: 0.6610 - val_mean_squared_error: 0.5319\n",
      "Epoch 4/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.6294 - mean_squared_error: 0.6701 - val_loss: 1.5600 - val_mean_squared_error: 2.5228\n",
      "Epoch 5/100\n",
      "382/382 - 1s - 3ms/step - loss: 0.5491 - mean_squared_error: 0.5043 - val_loss: 0.9025 - val_mean_squared_error: 0.8882\n",
      "Epoch 6/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.5162 - mean_squared_error: 0.4468 - val_loss: 1.1793 - val_mean_squared_error: 1.4490\n",
      "Epoch 7/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.4865 - mean_squared_error: 0.3958 - val_loss: 1.9954 - val_mean_squared_error: 4.0308\n",
      "Epoch 8/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.4312 - mean_squared_error: 0.3131 - val_loss: 1.7527 - val_mean_squared_error: 3.1169\n",
      "Epoch 9/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.4063 - mean_squared_error: 0.2830 - val_loss: 2.8626 - val_mean_squared_error: 8.2375\n",
      "Epoch 10/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.3625 - mean_squared_error: 0.2274 - val_loss: 2.2590 - val_mean_squared_error: 5.1430\n",
      "Epoch 11/100\n",
      "382/382 - 1s - 2ms/step - loss: 0.3014 - mean_squared_error: 0.1594 - val_loss: 2.0335 - val_mean_squared_error: 4.1729\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step\n",
      "\u001b[1m1017/1017\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step\n",
      "\n",
      "DNN Evaluation:\n",
      "Validation RMSE: 0.3712\n",
      "Test RMSE:       0.3714\n",
      "Test MAE:        0.2995\n",
      "Test R²:         -0.157\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build DNN\n",
    "dnn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # output layer for regression\n",
    "])\n",
    "\n",
    "dnn.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = dnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(dnn, X_val, y_val, X_test, y_test, \"DNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9120b43-0229-4a7a-aac9-fbc6036a43af",
   "metadata": {},
   "source": [
    "Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91dbc88-d017-4169-8c59-cedff6cd66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save a model\n",
    "# linear\n",
    "joblib.dump(lr, \"models/lr_model.pkl\")\n",
    "joblib.dump(ridge, \"models/ridge_model.pkl\")\n",
    "joblib.dump(lasso, \"models/lasso_model.pkl\")\n",
    "# random forest\n",
    "joblib.dump(rf, \"models/rf_model.pkl\")\n",
    "# boosting\n",
    "joblib.dump(xgb, \"models/xgb_model.pkl\")\n",
    "joblib.dump(lgbm, \"models/lgbm_model.pkl\")\n",
    "joblib.dump(cat, \"models/cat_model.pkl\")\n",
    "#knn\n",
    "joblib.dump(knn, \"models/knn_model.pkl\")\n",
    "#nn\n",
    "joblib.dump(dnn, \"models/dnn_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61220332-1e93-4cbf-98ab-5f0bd07df4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it later\n",
    "loaded_model = joblib.load(\"rf_model.pkl\")\n",
    "y_pred = loaded_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs5228_assignment)",
   "language": "python",
   "name": "cs5228_assignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
